{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39d1bee",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b0b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9dc591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/xavi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/xavi/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a63042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/processed/fake_news_combined_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77bd36d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_length</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump to keep Manhattan federal prosecutor Bha...</td>\n",
       "      <td>NEW YORK (Reuters) - Preet Bharara, the top fe...</td>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>trump keep manhattan federal prosecutor bharar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democratic Senator Wyden says he will vote for...</td>\n",
       "      <td>WASHINGTON (Reuters) - Democratic U.S. Senator...</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>democratic senator wyden say vote puerto rico ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.N. aid chief appeals for full lifting of Yem...</td>\n",
       "      <td>GENEVA (Reuters) - The United Nations appealed...</td>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>un aid chief appeal full lifting yemen blockad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump returns to hardline position on illegal ...</td>\n",
       "      <td>PHOENIX (Reuters) - Republican presidential no...</td>\n",
       "      <td>1</td>\n",
       "      <td>865</td>\n",
       "      <td>trump return hardline position illegal immigra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Syrian opposition must accept it has not won t...</td>\n",
       "      <td>GENEVA (Reuters) - Syria s opposition must acc...</td>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>syrian opposition must accept war un geneva re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump to keep Manhattan federal prosecutor Bha...   \n",
       "1  Democratic Senator Wyden says he will vote for...   \n",
       "2  U.N. aid chief appeals for full lifting of Yem...   \n",
       "3  Trump returns to hardline position on illegal ...   \n",
       "4  Syrian opposition must accept it has not won t...   \n",
       "\n",
       "                                                text  label  text_length  \\\n",
       "0  NEW YORK (Reuters) - Preet Bharara, the top fe...      1          620   \n",
       "1  WASHINGTON (Reuters) - Democratic U.S. Senator...      1           78   \n",
       "2  GENEVA (Reuters) - The United Nations appealed...      1          496   \n",
       "3  PHOENIX (Reuters) - Republican presidential no...      1          865   \n",
       "4  GENEVA (Reuters) - Syria s opposition must acc...      1          472   \n",
       "\n",
       "                                          clean_text  \n",
       "0  trump keep manhattan federal prosecutor bharar...  \n",
       "1  democratic senator wyden say vote puerto rico ...  \n",
       "2  un aid chief appeal full lifting yemen blockad...  \n",
       "3  trump return hardline position illegal immigra...  \n",
       "4  syrian opposition must accept war un geneva re...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define cleaner\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # remove URLs\n",
    "    text = re.sub(r'\\@w+|\\#','', text)                  # remove mentions and hashtags\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)             # remove punctuation/numbers\n",
    "    text = text.strip()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df[\"clean_text\"] = df[\"title\"].fillna('') + \" \" + df[\"text\"].fillna('')\n",
    "df[\"clean_text\"] = df[\"clean_text\"].apply(clean_text)\n",
    "\n",
    "# Save the cleaned version\n",
    "df.to_csv(\"../data/final_cleaned_news_data.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
